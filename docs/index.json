[{"content":"This blog post recalls my personal experience at a company that had a digital wallet service, used by over 3 million people.\nDuring my time there, my team and I were deeply involved in creating a new feature that was in high demand by our users. When we notified them about its launch, we didn\u0026rsquo;t expect the overwhelming response it received.\nA huge number of users immediately tried the new feature, leading to an unexpected and massive surge in traffic. Our tech infrastructure, unprepared for such a load, was overwhelmed and eventually collapsed.\nAfter recounting this challenging experience, now let\u0026rsquo;s look at some better ways to introduce new features without running into these problems using different strategies of Gradual Rollouts, a phased approach in engineering for releasing updates. It enables testing stability and performance with a limited audience, identifying issues with minimal overall user impact.\nDark Launching Dark Launching is primarily a backend technique that involves introducing a new (or modified) feature, which is then activated for current users without their knowledge. This technique provides insights into how the feature would be behaving in production, without actually impacting users.\nWe adjust the flow to call Feature 3 as it would in production, doing all the work but without displaying any results, so nobody can see that it\u0026rsquo;s doing it.\nDark launching enables test engineers to evaluate new features in a real-world setting without impacting users. This process allows for performance testing, issue detection, infrastructure scaling assessments and stress testing under actual traffic conditions. Essentially, it offers a safer, more effective way to ensure new updates are ready for broader release.\nðŸ’¡ The concept of Dark Launching has evolved over time, leading to some confusion. Nowadays, it\u0026rsquo;s often used interchangeably with the concept of Canary Release. Canary Release Canary Release is a method used to minimize the risk of deploying new versions by initially introducing the update to a small group of users. This approach involves gradually extending the update across the entire system.\nThis technique starts with the new version being deployed to a part of the infrastructure not yet accessed by users, and then the process continues by gradually routing some user traffic to the new version.\nThe term is derived from an old mining practice, where miners took canaries into mines as an early warning system against toxic gases. Just as the canary would alert miners to danger, a canary release detects potential issues in a software update before it affects all users.\nIn modern distributed systems, instead of using a router for this process, various strategies are employed. These include rolling out updates to specific geographic regions first or to specific user groups based on criteria like user behavior, device type, or membership tier. Load-based rollouts are another option, where the new version is deployed during off-peak hours or low-activity periods to minimize potential impact.\nFeature Toggles Alongside the mentioned strategies for implementing Canary Releases, Feature Toggles enable the introduction of new features within the same environment. This method facilitates incremental rollouts to selected user groups, streamlining the release process and reducing the need for maintaining multiple environments or versions.\nðŸ’¡ Feature Toggle is also referred to as Feature Flag in some engineering contexts, highlighting its role in enabling and disabling certain features. Shadow Testing Shadow testing is a technique used to compare the current environment with a new one that includes a new feature. Its purpose is to identify and reduce potential risks before releasing the new feature to users, all without users ever knowing it\u0026rsquo;s happening.\nIn shadow testing, we observe how real users interact with our system by examining their actual traffic, all without impacting the code or the experience of users in the production environment.\nA replica of the production environment is created to mimic real user traffic. This environment serves as a shadow of the production environment. The new feature is then tested in a different environment. After testing, the responses from both environments are compared by test engineers to identify any risks before introducing the new feature to the production environment.\nTL;DR GradualÂ RolloutÂ Strategy Description Dark Launching Deploying a feature in production without making it visible to users. The functionality is dark to users, but can be selectively enabled for testing purposes. Canary Release Rolling out a new feature incrementally to a small subset of users before a full deployment, often implemented through the use of Feature Toggles Shadow Testing Duplicating real traffic to a parallel new service version, which processes it without affecting or being noticed by users, allowing performance and stability testing under real conditions. Acknowledgements \u0026ldquo;The Top 10 Adages in Continuous Deployment\u0026rdquo; by C. Parnin et al. (2017)\n\u0026ldquo;Weâ€™re Doing It Live\u0026rdquo; by G. Schermann, J. Cito, P. Leitner, U. Zdun and H. C. Gall (2018).\n","permalink":"https://lmitelman.github.io/posts/silent-launches/","summary":"This blog post recalls my personal experience at a company that had a digital wallet service, used by over 3 million people.\nDuring my time there, my team and I were deeply involved in creating a new feature that was in high demand by our users. When we notified them about its launch, we didn\u0026rsquo;t expect the overwhelming response it received.\nA huge number of users immediately tried the new feature, leading to an unexpected and massive surge in traffic.","title":"The Art of Silent Launches"},{"content":"A few weeks ago, one of the best engineers on my team made an important comment in a pull request:\n\u0026ldquo;Remember not to break the Tell-Don\u0026rsquo;t-Ask principle.\u0026rdquo;\nâ€” Fernando Balmaceda, the great.\nLet\u0026rsquo;s delve into this concept a bit\u0026hellip;\nIn object-oriented software, a typical use case involves executing logic based on an object\u0026rsquo;s internal state. For instance, consider a scenario where we want to sound an alarm if a thermometer reaches a certain temperature:\nclass Thermometer { private temperature: number = 0; increaseTemperature(value: number): void { this.temperature += value; } getTemperature(): number { return this.temperature; } }; class Alarm { sound(): void { console.log(\u0026#39;RIIING!\u0026#39;); } }; In this \u0026ldquo;asking\u0026rdquo; approach, to detect the temperature and sound an alarm, we would have to:\nconst thermometer = new Thermometer(); thermometer.increaseTemperature(35); const temperature = thermometer.getTemperature(); if (temperature \u0026gt; 30) { const alarm = new Alarm(); alarm.sound(); }; However, following the Tell-Don\u0026rsquo;t-Ask principle suggests that the logic should reside within the object itself if it is related to that object. In other words, the thermometer should be responsible for sounding the alarm when it reaches a certain temperature. This promotes more object-oriented code as opposed to procedural code.\nProcedural code gets information then makes decisions. Object-oriented code tells objects to do things.\nWith this in mind, let\u0026rsquo;s refactor our classes using a \u0026ldquo;telling\u0026rdquo; approach:\nclass Thermometer { private temperature: number = 0; private alarm: Alarm; constructor(alarm: Alarm) { this.alarm = alarm; } increaseTemperature(value: number): void { this.temperature += value; if (this.temperature \u0026gt; 30) { this.alarm.sound(); } } }; class Alarm { sound(): void { console.log(\u0026#39;RIIING!\u0026#39;); } }; Now, instead of checking the thermometer\u0026rsquo;s internal status to sound the alarm, we \u0026ldquo;tell\u0026rdquo; the thermometer to handle that:\nconst alarm = new Alarm(); const thermometer = new Thermometer(alarm); thermometer.increaseTemperature(35); To summarize, it is acceptable to \u0026ldquo;ask\u0026rdquo; for the state of an object and then execute certain logic based on that information. However, if that logic is inherently related to the object, it should be moved and become the responsibility of the object itself. By adhering to the Tell-Don\u0026rsquo;t-Ask principle, we can create more maintainable and object-oriented code.\nAcknowledgements I would like to extend my heartfelt thanks to Fernando Balmaceda, whose comment sparked the idea for this post. His contributions and mentorship have played a significant role in shaping my approach to software engineering. \u0026ldquo;The Art of Enbugging\u0026rdquo; by Andy Hunt and Dave Thomas (2003). ","permalink":"https://lmitelman.github.io/posts/tell-dont-ask/","summary":"A few weeks ago, one of the best engineers on my team made an important comment in a pull request:\n\u0026ldquo;Remember not to break the Tell-Don\u0026rsquo;t-Ask principle.\u0026rdquo;\nâ€” Fernando Balmaceda, the great.\nLet\u0026rsquo;s delve into this concept a bit\u0026hellip;\nIn object-oriented software, a typical use case involves executing logic based on an object\u0026rsquo;s internal state. For instance, consider a scenario where we want to sound an alarm if a thermometer reaches a certain temperature:","title":"Tell-Donâ€™t-Ask"}]